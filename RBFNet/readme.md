## RBFNet

这篇...其实本身是不难的。但关键是在于这个`torch.exp`的问题。

我们都知道指数函数 $e^x$ 在 $x$ 稍微取大一点的时候这个数就会很大。比如取个什么 $e^{50}$ 基本上就可以等着爆浮点了。但是根据这老师给的数据。。。如果完全按照那个**径向基函数**的定义来算：
$$\rho\left ( x, c_i \right ) =e^{-\beta_i\left \| x-c_i \right \|^2 } $$

那这个数爆内存是迟早的事情。所以就很麻烦！必须要进行数据预处理。

我的想法就比较简单，直接对源数据中所有数据都除以10. 其实稳妥起见，我觉得除以 100， 1000都是没问题的。

然后我就直接对着验证集上的 loss 看效果。这个效果也是很差的...loss一直是很高的。但是好在每个epoch跑得都特别快，因为说到底还是个小样本的问题。那这么看的话我觉得问题也不算是太大，只要跑它个 1k 个epoch总能看到点效果。

但是按照西瓜书上的提示来看，
> 第一步，确定神经元的中心 $c_i$，常用的方式包括随机采样、聚类等；第二部，利用 BP 算法等来确定参数 $w_i$, $\beta_i$.

不觉得有哪里不对吗？每个神经元的中心（以前都是阈值）现在需要我来自己提前确定好，能更新的参数只有 $w_i$, $\beta_i$。那说白了这个网络还要预置一个聚类算法？有监督分类问题在做之前还要先无监督聚类……我不好说这玩意有啥意义。

总之先用随机采样做了一下，loss也是很大的，因为`torch.exp`不能接受很大的数（会报`inf`，`inf`值再带进去就直接是`nan`）。

总之是蛮无语的。既然是作业的话，做是肯定会好好做，但是做出的这个模型，我是不觉得是什么好东西。我的想法是要么把所谓的【中心 $c_i$】下放到普通参数中去慢慢更新，要么就换成多隐层。